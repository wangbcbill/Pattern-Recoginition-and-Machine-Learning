# -*- coding: utf-8 -*-
"""Project1_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zFZo6arneuQREwhejELXs_ukVu49Ig_f
"""

from google.colab import drive
drive.mount('/content/drive')

from os.path import exists
from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())
cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\.\([0-9]*\)\.\([0-9]*\)$/cu\1\2/'
accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'

!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision
import torch

class args(object):
    def __init__(self):
        self.epochs = 300
        self.batch_size = 100
        self.seed = 12345
        self.device = 0
        self.image_dir = '/content/drive/My Drive/Colab Notebooks/data/images/'
        self.landmark_dir = '/content/drive/My Drive/Colab Notebooks/data/landmarks/'
        self.male_img_dir = '/content/drive/My Drive/Colab Notebooks/data/male_images/'
        self.female_img_dir = '/content/drive/My Drive/Colab Notebooks/data/female_images/'
        self.male_landmark = '/content/drive/My Drive/Colab Notebooks/data/male_landmarks/'
        self.female_landmark = '/content/drive/My Drive/Colab Notebooks/data/female_landmarks/'
        self.path = '/content/drive/My Drive/Colab Notebooks/data/model/'
        self.log = '/content/drive/My Drive/Colab Notebooks/data/log/'
        self.appear_lr = 7e-4
        self.landmark_lr = 1e-4
        self.cuda = True
        
args = args()
print(torch.cuda.is_available())

!pip install Pillow==4.0.0
!pip install image

def applyAffineTransform(src, srcTri, dstTri, size) :
    
    # Given a pair of triangles, find the affine transform.
    warpMat = cv2.getAffineTransform( np.float32(srcTri), np.float32(dstTri) )
    
    # Apply the Affine Transform just found to the src image
    dst = cv2.warpAffine( src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )

    return dst


# Check if a point is inside a rectangle
def rectContains(rect, point) :
    if point[0] < rect[0] :
        return False
    elif point[1] < rect[1] :
        return False
    elif point[0] > rect[0] + rect[2] :
        return False
    elif point[1] > rect[1] + rect[3] :
        return False
    return True

#calculate delanauy triangle
def calculateDelaunayTriangles(rect, points):
    #create subdiv
    subdiv = cv2.Subdiv2D(rect);
    
    # Insert points into subdiv
    for p in points:
        p1=(int(p[0]),int(p[1]))
        if p1[1]<=rect[2]-1 and p1[0]<=rect[2]-1 and p1[1]>=rect[0] and p1[0]>=rect[0]:
            subdiv.insert(p1) 
    
    triangleList = subdiv.getTriangleList();
    
    delaunayTri = []
    
    pt = []    
        
    for t in triangleList:        
        pt.append((t[0], t[1]))
        pt.append((t[2], t[3]))
        pt.append((t[4], t[5]))
        
        pt1 = (t[0], t[1])
        pt2 = (t[2], t[3])
        pt3 = (t[4], t[5])        
        
        if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):
            ind = []
            #Get face-points (from 68 face detector) by coordinates
            for j in range(0, 3):
                for k in range(0, len(points)):                    
                    if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):
                        ind.append(k)    
            # Three points form a triangle. Triangle array corresponds to the file tri.txt in FaceMorph 
            if len(ind) == 3:                                                
                delaunayTri.append((ind[0], ind[1], ind[2]))
        
        pt = []        
            
    
    return delaunayTri

# Warps and alpha blends triangular regions from img1 and img2 to img
def warpTriangle(img1, img2, t1, t2) :

    # Find bounding rectangle for each triangle
    r1 = cv2.boundingRect(np.float32([t1]))
    r2 = cv2.boundingRect(np.float32([t2]))

    # Offset points by left top corner of the respective rectangles
    t1Rect = [] 
    t2Rect = []
    t2RectInt = []

    for i in range(0, 3):
        t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))
        t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))
        t2RectInt.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))

    w,h,num_chans = img1.shape
    # Get mask by filling triangle
    mask = np.zeros((r2[3], r2[2], num_chans), dtype = np.float32)
    cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0);

    # Apply warpImage to small rectangular patches
    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]
    #img2Rect = np.zeros((r2[3], r2[2]), dtype = img1Rect.dtype)
    
    size = (r2[2], r2[3])

    img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)
    if num_chans==1:
        img2Rect=np.reshape(img2Rect,(r2[3], r2[2], num_chans))
    
    img2Rect = img2Rect * mask

    # Copy triangular region of the rectangular patch to the output image
    if num_chans==1:
        img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ( 1.0 - mask )
     
    else:
        img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ( (1.0, 1.0, 1.0) - mask )
     
    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect 

###################################
def warp(Image,sc,tc):
    '''
    Image: the image to be warped
    sc: original landmarks
    tc: warped landmarks
    '''
    HW,_,_=Image.shape
    cornerps=[[0,0],[0,HW-1],[HW-1,0],[HW-1,HW-1]]
    #cornerps=[[0,0],[0,HW-1],[HW-1,0],[HW-1,HW-1],[0,np.floor(HW/2)],[np.floor(HW/2),0],[HW-1,np.floor(HW/2)],[np.floor(HW/2),HW-1]]

    scl=sc.astype(np.int64).tolist()+cornerps
    tcl=tc.astype(np.int64).tolist()+cornerps
    imgWarped = np.copy(Image);    
    rect = (0, 0, HW, HW)
    dt = calculateDelaunayTriangles(rect,tcl)
# Apply affine transformation to Delaunay triangles
    for i in range(0, len(dt)):
        t1 = []
        t2 = []
        
        #get points for img1, img2 corresponding to the triangles
        for j in range(0, 3):
            t1.append(scl[dt[i][j]])
            t2.append(tcl[dt[i][j]])
        
        warpTriangle(Image, imgWarped, t1, t2)
    return imgWarped

import torch
import torch.nn as nn
import torch.optim as optim


class appearance_autoencoder(nn.Module):
    def __init__(self):
        super(appearance_autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            # TODO: Fill in the encoder structure
            nn.Conv2d(3,16,kernel_size=3,stride=2,padding=1),
            nn.LeakyReLU(),
            nn.Conv2d(16,32,kernel_size=3,stride=2,padding=1),
            nn.LeakyReLU(),
            nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1),
            nn.LeakyReLU(),
            nn.Conv2d(64,128,kernel_size=3,stride=2,padding=1),
            nn.LeakyReLU(),
        )

        self.fc1 = nn.Sequential(                    
            # TODO: Fill in the FC layer structure
            nn.Linear(128*8*8,50),
            nn.LeakyReLU(),
        )

        self.decoder = nn.Sequential(
            # TODO: Fill in the decoder structure
            # Hint: De-Conv in PyTorch: ConvTranspose2d 
            nn.ConvTranspose2d(50,128,kernel_size=8,stride=1),
            nn.LeakyReLU(),
            nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=1),
            nn.LeakyReLU(),
            nn.ConvTranspose2d(64,32,kernel_size=4,stride=2,padding=1),
            nn.LeakyReLU(),
            nn.ConvTranspose2d(32,16,kernel_size=4,stride=2,padding=1),
            nn.LeakyReLU(),
            nn.ConvTranspose2d(16,3,kernel_size=4,stride=2,padding=1),
            nn.Sigmoid(),
        )

    def forward(self, x,fc):
            # TODO: Fill in forward pass
        if fc==False:
            x=self.encoder(x)
            z=self.fc1(x.view(-1,128*8*8)).cuda()
            x_recon=self.decoder(z.view(-1,50,1,1)).cuda()
            return x_recon,z
        
        else:
            x_recon=self.decoder(x.view(-1,50,1,1)).cuda()
            return x_recon           
        


class landmark_autoencoder(nn.Module):
    def __init__(self):
        super(landmark_autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            # TODO: Fill in the encoder structure
            nn.Linear(68*2,100),
            nn.LeakyReLU(),
            nn.Linear(100,10),
            nn.LeakyReLU(),
        )
        self.decoder = nn.Sequential(
            # TODO: Fill in the decoder structure
            nn.Linear(10,100),
            nn.LeakyReLU(),
            nn.Linear(100,68*2),
            nn.Sigmoid(),
        )

    def forward(self, x,fc):
            # TODO: Fill in forward pass
        if fc==False:
            x=x.view(-1,68*2)
            z=self.encoder(x).cuda()
            x_recon=self.decoder(z).cuda()
            x_recon=x_recon.view(-1,68,2)
            return x_recon,z
        else:
            x_recon=self.decoder(x).cuda()
            x_recon=x_recon.view(-1,68,2)
            return x_recon


class autoencoder(object):
    def __init__(self, appear_lr, landmark_lr, use_cuda):
        self.appear_model = appearance_autoencoder()
        self.landmark_model = landmark_autoencoder()
        self.use_cuda = use_cuda
        if use_cuda:
            self.appear_model.cuda()
            self.landmark_model.cuda()
        self.criterion = nn.MSELoss()
        self.appear_optim = optim.Adam(self.appear_model.parameters(), lr=appear_lr)
        self.landmark_optim = optim.Adam(self.landmark_model.parameters(), lr=landmark_lr)
        
    def train_appear_model(self, epochs, trainloader):
        self.appear_model.train()
        epoch = 0
        # TODO: Train appearance autoencoder
        for epoch in range(0,epochs):
            training_loss=0
            for x in trainloader:
                if self.use_cuda:
                    x=x.cuda()
                
                self.appear_optim.zero_grad()
                x_recon,z=self.appear_model(x,False)
                loss=self.criterion(x_recon,x)
                loss.backward()
                self.appear_optim.step()
                
                training_loss+=loss.item()
            print('Appear Training Epoch:{},Loss:{:.6f}'.format(epoch,training_loss/len(trainloader)))
        
    def train_landmark_model(self, epochs, trainloader):
        self.landmark_model.train()
        epoch = 0
        # TODO: Train landmark autoencoder
        for epoch in range(0,epochs):
            training_loss=0
            for x in trainloader:
                if self.use_cuda:
                    x=x.cuda()
                
                self.landmark_optim.zero_grad()
                x_recon,z=self.landmark_model(x,False)
                loss=self.criterion(x_recon,x)
                loss.backward()
                self.landmark_optim.step()
                
                training_loss+=loss.item()
            print('Landmark Training Epoch:{},Loss:{:.6f}'.format(epoch,training_loss/len(trainloader)))

    def test_appear_model(self, testloader):
        self.appear_model.eval()
        # TODO: Test appearance autoencoder
        
        recon_appear=[]
        appear_latent=[]
        testing_loss=0
        for x in testloader:
            if self.use_cuda:
                x=x.cuda()
            
            x_recon,z=self.appear_model(x,False)
            appear_latent.append(z)
            recon_appear.append(x_recon)
            loss=self.criterion(x_recon,x)
            
                
            testing_loss+=loss.item()
        
        testing_loss=testing_loss/len(testloader)
#        print('Appear Testing Loss:{:.6f}'.format(testing_loss/len(testloader)))   
        return recon_appear,appear_latent,testing_loss
    
    def test_landmark_model(self, testloader):
        self.landmark_model.eval()
        # TODO: Test landmark autoencoder
        
        recon_landmark=[]
        landmark_latent=[]
        testing_loss=0
        for x in testloader:
            if self.use_cuda:
                x=x.cuda()
            
            x_recon,z=self.landmark_model(x,False)
            landmark_latent.append(z)
            recon_landmark.append(x_recon)
            loss=self.criterion(x_recon,x)
            
                
            testing_loss+=loss.item()
            
        testing_loss=testing_loss/len(testloader)
#        print('Landmark Testing Loss:{:.6f}'.format(testing_loss/len(testloader)))  
        return recon_landmark,landmark_latent, testing_loss

    def decoder_appear(self,appear_latent):
        
        recon_appear=[]
        for x in appear_latent:
            if self.use_cuda:
                x=x.cuda()
                
            x_recon=self.appear_model(x,True).cuda()
            recon_appear.append(x_recon)
        
        return recon_appear

    def decoder_landmark(self,landmark_latent):
        
        recon_landmark=[]
        for x in landmark_latent:
            if self.use_cuda:
                x=x.cuda()
                
            x_recon=self.landmark_model(x,True).cuda()
            recon_landmark.append(x_recon)
        
        return recon_landmark

import os
import numpy as np
import argparse
import matplotlib.pyplot as plt
import skimage
from skimage import io, transform
import scipy.io as sio

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
import cv2

# Read Dataset
class data_reader(object):
    def __init__(self, root_dir, file_str_len, origin_name, file_format):
        self.root_dir = root_dir
        self.file_str_len = file_str_len
        self.origin_name = origin_name
        self.file_format = file_format

    def read(self, split, read_type):
        files_len = len([name for name in os.listdir(self.root_dir) 
                        if os.path.isfile(os.path.join(self.root_dir, name))])
        counter = 0
        idx = counter
        dataset = []
        train_dataset = []
        test_dataset = []
        while counter < files_len:
            name = self.origin_name + str(idx)
            if len(name) > self.file_str_len:
                name = name[len(name)-self.file_str_len:]
            try:
                if read_type == 'image':
                    data = io.imread(self.root_dir + name + self.file_format)
                elif read_type == 'landmark':
                    mat_data = sio.loadmat(self.root_dir + name + self.file_format)

                    data = mat_data['lms']
                dataset.append(data)
                counter += 1
            except FileNotFoundError:
                pass
            idx += 1
        train_dataset = dataset[:split]
        test_dataset = dataset[split:]
        return train_dataset, test_dataset

# Construct Dataset
class ImgToTensor(object):
    def __call__(self, sample):
        sample = sample.transpose((2, 0, 1))
        return torch.tensor(sample, dtype=torch.float32)/255

class LandmarkToTensor(object):
    def __call__(self, sample):
        return torch.tensor(sample, dtype=torch.float32)/128

class dataset_constructor(Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        sample_data = self.dataset[idx]
        if self.transform:
            sample_data = self.transform(sample_data)
        return sample_data

#args = parser.parse_args()
args.cuda = torch.cuda.is_available()
torch.cuda.set_device(args.device)

if not os.path.exists(args.path):
    os.makedirs(args.path)
if not os.path.exists(args.log):
    os.makedirs(args.log)

if args.cuda:
    torch.cuda.manual_seed(args.seed)

face_images_reader = data_reader(args.image_dir, 6, '000000', '.jpg')
face_images_train, face_images_test = face_images_reader.read(split=800, \
                                                                read_type='image')
face_landmark_reader = data_reader(args.landmark_dir, 6, '000000', '.mat')
face_landmark_train, face_landmark_test = face_landmark_reader.read(split=800, \
                                                                read_type='landmark')  

sum_landmark=np.zeros([68,2])
for i in range(800):    
    sum_landmark+=face_landmark_train[i]

mean_landmark=sum_landmark/800
  
face_images_train_align=np.copy(face_images_train)  
for i in range(800):
     face_images_train_align[i]=warp(face_images_train[i],face_landmark_train[i],mean_landmark)

face_images_test_align=np.copy(face_images_test)
for i in range(200):
     face_images_test_align[i]=warp(face_images_test[i],face_landmark_test[i],mean_landmark)

face_trainset = dataset_constructor(face_images_train_align, transform=transforms.Compose([
                                                                    ImgToTensor()]))
face_testset = dataset_constructor(face_images_test_align, transform=transforms.Compose([
                                                                    ImgToTensor()]))
face_trainloader = torch.utils.data.DataLoader(face_trainset, \
                                                    batch_size=args.batch_size, \
                                                    shuffle=False, \
                                                    num_workers=0)
face_testloader = torch.utils.data.DataLoader(face_testset, \
                                                    batch_size=args.batch_size, \
                                                    shuffle=False, \
                                                    num_workers=0)

landmark_trainset = dataset_constructor(face_landmark_train, transform=transforms.Compose([
                                                                    LandmarkToTensor()]))
landmark_testset = dataset_constructor(face_landmark_test, transform=transforms.Compose([
                                                                    LandmarkToTensor()]))
landmark_trainloader = torch.utils.data.DataLoader(landmark_trainset, \
                                                        batch_size=args.batch_size, \
                                                        shuffle=False, \
                                                        num_workers=0)
landmark_testloader = torch.utils.data.DataLoader(landmark_testset, \
                                                        batch_size=args.batch_size, \
                                                        shuffle=False, \
                                                        num_workers=0)

face_autoencoder = autoencoder(args.appear_lr, args.landmark_lr, use_cuda=True)

face_autoencoder.train_appear_model(epochs = args.epochs, trainloader = face_trainloader)

recon_appear,appear_latent,test_lost_appear=face_autoencoder.test_appear_model(testloader = face_testloader)

face_autoencoder.train_landmark_model(epochs = args.epochs, trainloader = landmark_trainloader)

recon_landmark,landmark_latent,test_lost_landmark=face_autoencoder.test_landmark_model(testloader = landmark_testloader)

recon_appear[0]=recon_appear[0].cpu()
recon_appear[1]=recon_appear[1].cpu()
recon_appear_all=np.concatenate((recon_appear[0].detach().numpy(),recon_appear[1].detach().numpy()),axis=0)
recon_landmark[0]=recon_landmark[0].cpu()
recon_landmark[1]=recon_landmark[1].cpu()
recon_landmark_all=np.concatenate((recon_landmark[0].detach().numpy(),recon_landmark[1].detach().numpy()),axis=0)

recon_appear_rgb=np.zeros([200,128,128,3])
recon_image=np.zeros([200,128,128,3])
for i in range(200):
  recon_appear_rgb[i,:,:,:]=recon_appear_all[i,:,:,:].transpose(1,2,0)
  recon_image[i,:,:,:]=warp(recon_appear_rgb[i,:,:,:],mean_landmark,128*recon_landmark_all[i,:,:])

def plot(samples,Nh,Nc,channel,IMG_HEIGHT, IMG_WIDTH):
    fig = plt.figure(figsize=(Nc, Nh))
    plt.clf()
    gs = gridspec.GridSpec(Nh, Nc)
    gs.update(wspace=0.05, hspace=0.05)

    for i, sample in enumerate(samples[0:Nh*Nc,:,:,:]):
        ax = plt.subplot(gs[i])
        plt.axis('off')
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect('equal')
        if channel==1:
            image=sample.reshape(IMG_HEIGHT, IMG_WIDTH)
            immin=(image[:,:]).min()
            immax=(image[:,:]).max()
            image=(image-immin)/(immax-immin+1e-8)
            plt.imshow(image,cmap ='gray')
        else:
            image=sample.reshape(IMG_HEIGHT, IMG_WIDTH,channel)
            immin=(image[:,:,:]).min()
            immax=(image[:,:,:]).max()
            image=(image-immin)/(immax-immin+1e-8)
            plt.imshow(image)

import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec

plot(recon_image[0:20],20,10,3,128,128)

plot(np.asarray(face_images_test)[0:20],20,10,3,128,128)

_,appear_latent_train,_=face_autoencoder.test_appear_model(testloader = face_trainloader)

_,landmark_latent_train,_=face_autoencoder.test_landmark_model(testloader = landmark_trainloader)

#appear_latent[0]=appear_latent[0].cpu()
#appear_latent[1]=appear_latent[1].cpu()
#appear_latent_test=np.concatenate((appear_latent[0].detach().numpy(),appear_latent[1].detach().numpy()),axis=0)
appear_latent_train[0]=appear_latent_train[0].cpu()
appear_latent_train[1]=appear_latent_train[1].cpu()
appear_latent_train_all=np.concatenate((appear_latent_train[0].detach().numpy(),appear_latent_train[1].detach().numpy()),axis=0)
#appear_latent_all=np.concatenate((appear_latent_train_all,appear_latent_test),axis=0)

var_appear=np.zeros([50])
mean_appear=np.zeros([50])
for i in range(50):
  var_appear[i]=np.var(appear_latent_train_all[:,i])
  mean_appear[i]=np.mean(appear_latent_train_all[:,i])

appear_rank=np.argsort(-var_appear)

np.random.seed(231)
appear0_latent=appear_latent_train_all[2]
x=np.zeros([4,10])
for i in range(4):
  x[i,:]=np.random.normal(mean_appear[appear_rank==i][0],5*np.sqrt(var_appear[appear_rank==i][0]),10)
  img=np.zeros([10,128,128,3])
  for j in range(10):
    appear0_latent[appear_rank==i]=x[i,j]
    img[j,:,:,:]=face_autoencoder.decoder_appear(appear_latent=torch.utils.data.DataLoader(torch.tensor(appear0_latent.reshape([50,1]),dtype=torch.float32), \
                                                    batch_size=args.batch_size, \
                                                    shuffle=False, \
                                                    num_workers=0))[0].cpu().detach().numpy().transpose(0,2,3,1)
  plot(img,4,10,3,128,128)

plot(face_images_train_align[2].reshape(1,128,128,3),1,1,3,128,128)

landmark_latent_train[0]=landmark_latent_train[0].cpu()
landmark_latent_train[1]=landmark_latent_train[1].cpu()
landmark_latent_train_all=np.concatenate((landmark_latent_train[0].detach().numpy(),landmark_latent_train[1].detach().numpy()),axis=0)

var_landmark=np.zeros([10])
mean_landmark_latent=np.zeros([10])
for i in range(10):
  var_landmark[i]=np.var(landmark_latent_train_all[:,i])
  mean_landmark_latent[i]=np.mean(landmark_latent_train_all[:,i])

landmark_rank=np.argsort(-var_landmark)

np.random.seed(231)
landmark0_latent=landmark_latent_train_all[2]
x=np.zeros([2,10])
for i in range(2):
  x[i,:]=np.random.normal(mean_landmark_latent[landmark_rank==i][0],np.sqrt(var_landmark[landmark_rank==i][0]),10)
  ld=np.zeros([10,68,2])
  img=np.zeros([10,128,128,3])
  for j in range(10):
    landmark0_latent[landmark_rank==i]=x[i,j]
    ld[j,:,:]=face_autoencoder.decoder_landmark(landmark_latent=torch.utils.data.DataLoader(torch.tensor(landmark0_latent.reshape([1,10]),dtype=torch.float32), \
                                                    batch_size=args.batch_size, \
                                                    shuffle=False, \
                                                    num_workers=0))[0].cpu().detach().numpy()
    img[j,:,:,:]=warp(face_images_train_align[2],mean_landmark,128*ld[j,:,:])
  plot(img,2,10,3,128,128)